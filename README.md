ğŸ“„ README â€” Customer Churn Reporting & Visualization Platform

## ğŸ¥ Demo Video


ğŸ”— [Ø§Ø¶ØºØ· Ù‡Ù†Ø§ Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¹Ù„Ù‰ Google Drive](https://drive.google.com/file/d/1bJ5uq-vqKlLI7HIEcKcDXonw5XNYD5d4/view?usp=drive_link)


ğŸ“Œ Project Name:
Customer Churn Reporting & Visualization Platform

ğŸ“Œ Track:
Data Engineering â€” DEPI

âœ… Objective
This project implements a complete end-to-end data engineering pipeline to analyze and understand customer churn behavior for a telecom company.

It covers the full data lifecycle:

Data ingestion from MySQL

Analytical warehousing using DuckDB

Data transformation & modeling with dbt

Workflow automation using Apache Airflow

Interactive visualization using Dash & Plotly

ğŸ—ï¸ 1. Environment Setup Guide

Below is the list of required tools and installation instructions.

Tool	Purpose	Installation
Python â‰¥ 3.9	Main programming language	python.org/downloads
MySQL Server	Transactional source database	dev.mysql.com/downloads/mysql
DuckDB	Analytical local data warehouse	pip install duckdb
Apache Airflow	Pipeline orchestration	pip install apache-airflow
dbt-duckdb	Data transformation & modeling	pip install dbt-core dbt-duckdb
Dash & Plotly	Visualization	pip install dash plotly
Pandas	Data manipulation	pip install pandas
MySQL Connector	Python â†” MySQL connection	pip install mysql-connector-python
ğŸ“ 2. Project Structure
Project_Customer_Churn_Reporting__Visualization_Platform/
â”‚
â”œâ”€ data/
â”‚   â”œâ”€ customer_churn.csv
â”‚   â”œâ”€ customer_churn_warehouse.duckdb
â”‚
â”œâ”€ sql/
â”‚   â””â”€ schema.sql
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ data_generator.py
â”‚   â”œâ”€ load_to_mysql.py
â”‚   â”œâ”€ mysql_to_duckdb.py
â”‚   â”œâ”€ db.py
â”‚   â”œâ”€ etl.py
â”‚   â”œâ”€ plotly_report.py
â”‚   â”œâ”€ app_dash.py
â”‚
â”œâ”€ customer_churn_dbt/
â”‚   â”œâ”€ dbt_project.yml
â”‚   â”œâ”€ models/
â”‚   â”‚   â”œâ”€ staging/
â”‚   â”‚   â”‚   â”œâ”€ staging_customer_churn.sql
â”‚   â”‚   â”‚   â””â”€ staging_customer_churn.yml
â”‚   â”‚   â”œâ”€ intermediate/
â”‚   â”‚   â”‚   â””â”€ intermediate_customer_metrics.sql
â”‚   â”‚   â”œâ”€ marts/
â”‚   â”‚   â”‚   â””â”€ fact_churn.sql
â”‚
â”œâ”€ airflow_dags/
â”‚   â””â”€ churn_pipeline_dag.py
â”‚
â”œâ”€ docs/
â”‚   â””â”€ Technical_Documentation_Customer_Churn.pdf
â”‚
â”œâ”€ outputs/
â”‚   â””â”€ churn_report.html
â”‚
â””â”€ README.md

ğŸ” 3. Environment Configuration (.env)

Create a .env file in the root directory:

MYSQL_HOST=localhost
MYSQL_USER=root
MYSQL_PASSWORD=your_password
MYSQL_DB=customer_churn_db

DUCKDB_PATH=./data/customer_churn_warehouse.duckdb

ğŸ§± 4. Architecture Overview

The pipeline has five functional layers:

âœ… 1. Data Ingestion Layer

Load CSV into MySQL using Python and Pandas.

âœ… 2. Data Warehousing Layer

Migrate data from MySQL â†’ DuckDB for analytical queries.

âœ… 3. Transformation Layer

Use dbt for:

Transformations

Testing

Documentation

Model lineage

âœ… 4. Orchestration Layer

Airflow automates:

ETL tasks

dbt runs

Daily scheduled pipelines

âœ… 5. Visualization Layer

A Dash + Plotly dashboard connects to DuckDB for interactive charts.

ğŸ“Š 5. Documentation & Diagrams

The project includes:

Data Flow Diagram:
Shows movement from CSV â†’ MySQL â†’ DuckDB â†’ dbt â†’ Dash.

ERD:
Star schema:

fact_churn

dim_customer

dim_service

dim_geography

dbt Model Lineage:
Visualization of staging â†’ intermediate â†’ mart dependencies.

Setup Guide & Architecture Overview
Included in /docs/Technical_Documentation_Customer_Churn.pdf

âœ… 6. Conclusion

This project demonstrates a complete and scalable data engineering pipeline using:

Python & Pandas for ingestion

MySQL for transactional storage

DuckDB as a local data warehouse

dbt for data modeling

Airflow for orchestration

Dash for visualization

It provides a reproducible workflow for telecom churn analysis and reflects the skills taught in the DEPI Data Engineering track.
